[lib]

[lib.logging]
enabled = true
file = false

[lib.sim]

[lib.sim.slack]
init_as_upper_bound = true
use_threshold_upper = false # whether to overwrite slack upper bound or not if slack falls below threshold
overwrite_upper_bound = 1.0 # in hours -- value to use if upper bound should be overwritten
# threshold values
threshold_upper = 2.0 # in hours
# defaults and ranges
default_lower_bound = 0.0 # in hours (included in initial slack range)
min_range = -100.0 # in hours -- minimum range (slack lower bound and upper bound) which must be adhered to, can be smaller after slack adaption
max_range = 100.0 # in hours -- maximum range (slack lower bound and upper bound) which must be adhered to, can be smaller after slack adaption
# slack adaption
adaption = true
# !! vvv - currently without effect - vvv
adaption_min_upper_bound = 1.0 # in hours -- minimum upper bound if slack is adapted
adaption_min_lower_bound = 0.0 # in hours -- minimum lower bound if slack is adapted

[lib.gym_env]
sim_dur_weeks = 39
buffer_size = 20
job_pool_size_min = 1  # >1: use batching with shuffling
job_pool_size_max = 10  # >1: use batching with shuffling
dispatcher_seq_rule = 'EDD'
dispatcher_alloc_rule = 'LOAD_TIME_REMAINING'

[lib.gym_env.WIP]
factor_WIP = nan # nan: do not apply
use_WIP_targets = true # use linearly generated WIP-levels from table "WIP_targets"
WIP_relative_targets = [2.75, 3.875, 5.0] # ignored if "use_WIP_targets" = true
# [0.5, 3, 6]
# [0.5,]
# [1.5, 0.5, 2.5, 5, 3.5]
# [3.5, 4.25, 5]
# [0.5, 1, 1.75]
WIP_level_cycles = 5 # how many full cycles with all WIP levels should be performed
WIP_relative_planned = 2.75
alpha = 10

[lib.gym_env.WIP_targets]
min = 0.5 # 0.5
max = 5 # 5
number_WIP_levels = 5 # must be odd


[train]

[train.system]
multiprocessing = false
number_processes = nan # nan: use num CPU cores of machine
save_state_actions = true # currently not compatible with multiprocessing

[train.files]
overwrite_folders = true
continue_learning = false
folder_tensorboard = 'tensorboard'
folder_models = 'models'
model_name = 'PPO_mask'
filename_pretrained_model = '2025-01-17--15-36-17_pyf_sim_PPO_mask_TS-1310720'

[train.experiment]
exp_number = 13
env_structure = '1-2-3'
job_generation_method = 'VarIdeal'
feedback_mechanism = 'Slack'

[train.model.inputs]
normalise_obs = true
normalise_rew = true

[train.model.seeds]
rng = nan # nan: use random state
eval = [1, 42, 100, 300, 427]

[train.model.arch]
batch_size = 1024
sb3_arch = {pi = [64, 64], vf = [64, 64]}

[train.runs]
ts_till_update = 2048
total_updates = 100_000
updates_till_eval = 2
updates_till_savepoint = 16
num_eval_episodes = 1 # based upon number of eval seeds
reward_threshold = nan # nan: do not apply

[train.env]
randomise_reset = true

[train.sb3]
show_progressbar = false


[test]
use_train_config = false # check removal
seeds = [1, 42, 100, 300, 427]

[test.files]
target_folder = '2025-03-24-17__1-2-3__VarIdeal__Slack'
filename_target_model = '2025-03-10--08-12-07_pyf_sim_PPO_mask_TS-204800001'

[test.inputs]
normalise_obs = true

[test.runs]
num_episodes = 1
perform_agent = true
perform_benchmark = false


[tensorboard]
use_train_config = true

[tensorboard.files]
exp_folder = '2025-02-20-01__1-2-3__VarIdeal__Slack'
